Feature 1 — Text → Healing Music (music-only)
User (chooses 30s / 3m / 5m in UI)
→ Public API /compose/music
→ Therapist AI (gpt-oss-20b) → “Therapy Plan” (music knobs + nl_description)
   (or: Direct Plan from UI hints if you bypass therapist here)
→ Router (duration/engine rules)
→ Engine Adapter (tokens for Indara | prompt+params for Vendor)
→ Music Engine (Indara 30s or Vendor 3–5m)
→ Music WAV
→ (Export M4A + store plan & assets)
→ CDN
→ Response (music_url[, m4a], plan, nl_description)

Feature 2 — Text → Meditation Session (music + TTS)
User (chooses 30s / 3m / 5m in UI)
→ Public API /compose/session
→ Therapist AI (gpt-oss-20b) → “Therapy Plan” (music knobs + TTS SSML + nl_description)
→ Router (duration/engine rules)
→ Engine Adapter (tokens for Indara | prompt+params for Vendor)
→ Music Engine (Indara 30s or Vendor 3–5m) → Music WAV
↘ TTS Engine (SSML → Voice WAV)
→ Mixing + Loudness (auto-duck, −19 LUFS mono)
→ Final M4A (+ keep WAV masters)
→ CDN
→ Response (mix_url, music_url, tts_url, lufs, plan, nl_description)

Core flow:
1) Endpoints (match your two features)

POST /compose/music
Text → healing music only (no voice).

POST /compose/session
Text → meditation session (healing music + TTS guidance + final mixed track).

Both endpoints accept the same core fields; the session endpoint also accepts optional TTS hints.

Common request fields (from your frontend):

user_text – what they type (e.g., “I want to calm down”)

duration_sec – 30 | 180 | 300 (you can send 30/180/300)

hints (optional) – { bpm, key_mode, genre, moods[], instrument[], keywords[], avoidances[] }

engine (optional) – "indara-30s" | "vendor-3m" | "vendor-5m" | "auto" (default: auto)

Extra (session only):

tts (optional) – { voice_hint, target_lufs } (defaults exist)

2) Routing logic (server-side; the frontend doesn’t care)

Step A — Choose engine (based on duration unless overridden):

duration_sec = 30 → Indara-30s (your Stage-B model)

duration_sec = 180 → Vendor-3m

duration_sec = 300 → Vendor-5m

If engine is explicitly provided in the request, honor it.

Step B — Sync vs Async:

30s: treat as synchronous (return result in the same response).

3 or 5 min: treat as job-based: return { job_id, status:"processing" }, and expose GET /jobs/{job_id} for the client to poll (or use webhooks if you prefer).

(This keeps your UX snappy and predictable.)

3) Intake & planning (identical for both endpoints)

Therapist AI intake (gpt-oss-20b, Harmony/tool calling, 3–4 short turns)
Produces a single Therapy Plan object with:

summary (one sentence for logs)

music (structured fields aligned to your metadata: intent, duration_sec, bpm, key_mode, genre, moods[], instrument[], keywords[], sample_rate (default 32000), energy_curve (optional))

tts (SSML, voice hint, loudness target) — ignored in /compose/music

nl_description (1–2 sentence human description; for QA/search/future conditioning)

Validation & defaults

If anything is missing, fill deterministic defaults (e.g., intent→BPM range, calm→minor key, approved vocab for moods/instruments).

Snap duration_sec to your three choices (30/180/300).

Note: If your music-only feature already collects enough sliders/toggles, you can optionally bypass the therapist step for /compose/music and build the plan directly from UI fields. The session endpoint should keep the therapist step to craft the SSML.

4) Engine adapters (what each backend expects)

A) Indara-30s (your model)

Convert the Plan’s music into Stage-B segments in 12-second bins:

Tokens per bin: [FR=50HZ_NQ4] [POS=START|MID|END] [POS_BIN=00..] [BPM=###] [KEY=F#MIN] [ENERGY=0.20] [SEC=AUTO_INTRO|AUTO_BODY|AUTO_OUTRO]

Build a gentle energy curve: down-ramp intro → low/stable body → soft outro.

Output: music.wav (32 kHz mono master recommended).

B) Vendor-3m / Vendor-5m

Convert the same Plan into a vendor prompt & params:

Prompt includes: intent, BPM, key, genre, moods, instruments, keywords, structure notes (intro/body/outro), “no vocals,” smooth dynamics.

Params include: duration (180 or 300), any supported controls (seed/style).

Output: music.wav (resample to your standard if needed).

5) Feature pipelines
(1) Text → Healing Music (/compose/music)

Includes: Intake → Plan → Route → Generate Music → Export/Store → Deliver

Generate music only according to the selected engine.

Store:

therapy_summary, therapy_plan

composer_plan (Indara) or vendor_prompt_plan (Vendor)

music.wav (master), optional music.m4a (delivery), waveform.json

Response (sync for 30s; async “done” for 3/5m):

engine, music_url, waveform_url (optional), plan, nl_description

(2) Text → Meditation Session (/compose/session)

Includes: Intake → Plan → Route → Generate Music → Generate TTS → Mix & Loudness → Export/Store → Deliver

Music: as above (Indara or Vendor, based on duration).

TTS: render tts.script_ssml to voice.wav (cache common lines).

Mix: sidechain-duck music under voice (≈−10 to −12 dB while speaking; gentle attack/release); normalize final to −19 LUFS (mono).

Store:

All the items from music-only plus voice.wav, mix.wav (master), mix.m4a (delivery)

Response (sync 30s; async “done” 3/5m):

engine, music_url, tts_url (optional), mix_url, lufs, plan, nl_description

6) Storage & CDN (both endpoints)

Save masters (*.wav) and delivery files (*.m4a) to S3/Supabase.

Put a CDN in front (CloudFront/Cloudflare/etc.).

Set Cache-Control and use content-hash keys for dedupe.

Always return URLs to the frontend.

7) Observability & controls

Per engine: error rate, latency, cost, fallbacks taken.

Per session: turns to completion, schema pass rate, re-generate rate.

Audio QA: integrated LUFS, true peak, average duck depth.

Safety: therapist prompt enforces non-clinical tone; add crisis guidance text.

8) Fallbacks (keep UX smooth)

Vendor slow/fails (3/5m): return a high-quality 60–90s loop (two crossfaded 30s chunks from Indara) immediately; complete the long track in the background and update the job later.

TTS fails (session): deliver music-only plus on-screen guidance; allow “add voice later”.

Missing fields: apply defaults; never hard-fail for optional fields.

9) Versioning (traceable results)

Tag everything on each job:
therapist_prompt@YYYY-MM-DD, tool_schema@vX, indara-30s@model_id, vendor@version.

Store the exact plan and the exact adapter payload you sent to the engine/TTS with the assets.

ops layers:
10) Analytics & quality loop — wrap the whole flow
Log per request: turns-to-completion, schema pass, re-generate.
Audio QA after mix: LUFS, peak, duck-depth.
Engine dashboards: cost & latency (Vendor vs Indara).
Run A/Bs (energy curves, SSML phrasing). Weekly review to tighten defaults.
11) Safety & tone — at Therapist AI + API ingress
System prompt enforces warm, non-clinical tone; crisis guidance.
Moderation / blocklist before plan generation; human override path.
12) Versioning & rollbacks — at Router & storage
Tag: therapist_prompt@date, tool_schema@vX, indara-30s@model_id, vendor@ver.
Store exact plan + adapter params with assets. Blue/green behind adapters.
13) Cost & latency controls — Router + Engines + TTS
Cache TTS phrases; cache popular 30s beds.
Pre-warm vendor for peak; per-user rate limits; engine backoff/retry.
14) Fallbacks & graceful degradation — Router + Mixer
Vendor timeout → instant 60–90s loop (crossfaded 30s chunks) + continue longform in background.
Missing fields → deterministic defaults.
TTS down → deliver music-only + on-screen guidance.
15) Data model — Storage layer
sessions, therapy_plan, composer_plan/vendor_plan, assets, analytics.
Persist plan + versions for reproducibility.
17) Deployment topology — infra layout
API gateway (auth/rate-limit)
Therapist service (gpt-oss)
Planner + Router (stateless)
Engines: Indara-30s, Vendor bridge
TTS adapter, Mixer worker
Object storage + CDN
Metrics/logs (APM + audio QA)
18) Pre–go-live checklist — gating criteria
Final system prompt + single tool schema.
Approved vocab (genre/moods/instruments/keywords).
Intent→defaults (BPM/KEY/energy curve).
Routing rules/timeouts; loudness/ducking targets.
Safety copy.
Success metrics (e.g., ≥90% schema pass; ≥80% completion ≤4 turns; <10% re-gen).
